{
  "index": {
    "max_ngram_diff": "3",
    "analysis": {
      "analyzer": {
        "word_analyzer": {
          "tokenizer": "text_tokenizer",
          "filter": [
            "lowercase"
          ]
        }
      },
      "tokenizer": {
        "text_tokenizer": {
          "type": "ngram",
          "min_gram": 2,
          "max_gram": 5,
          "token_chars": [
            "letter",
            "digit",
            "symbol",
            "punctuation"
          ]
        }
      }
    }
  }
}